{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXPt7aW2Utzq"
   },
   "outputs": [],
   "source": [
    "# Take-Home Coding Assessment\n",
    "\n",
    "# Task 1: Description: Write a program that reads a file and finds matches against a predefined set of words. There can be up to 10K entries in the list of predefined words.\n",
    "# Requirement details:\n",
    "# Input file is a plain text (ascii) file, every record separated by a new line.\n",
    "# For this exercise, assume English words only\n",
    "# The file size can be up to 20 MB\n",
    "# The predefined words are defined in a text file, every word separated by a newline. Use a sample file of your choice for the set of predefined keywords for the exercise.\n",
    "# Thanks,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdX-vnzWUxHh",
    "outputId": "26671c42-bbfb-47c2-c88a-ebe855d63338"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time: 0.42473292350769043\n",
      "Matched words: 27044\n"
     ]
    }
   ],
   "source": [
    "# With basic python operations\n",
    "\n",
    "import time\n",
    "\n",
    "startTime = time.time()\n",
    "predefinedWords = {}\n",
    "\n",
    "#reading the predefined words into a dictionary for easy access. \n",
    "# For, a system holding predefined data in GB/TB, we can use a distrbuted cache to achieve this purpose.\n",
    "with open('predefined_words.txt','r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "      predefinedWords[line.strip()] = 1\n",
    "# print(len(predefinedWords))\n",
    "\n",
    "# reading the input Data and matching the words with the predefined ones in the dictionary\n",
    "# Here, I am reading all lines at once since my system is capable of holding the data in memory. but, if we are gonna\n",
    "# deal with much large data sets, its better to read and write data in batches. so, that each batch fits into the memory.\n",
    "matched_word_cnt = 0\n",
    "matched_words_str = ''\n",
    "with open('input.txt','r') as inputFile:\n",
    "    lines = inputFile.readlines()\n",
    "    for line in lines:\n",
    "      word = line.strip()\n",
    "      if(word in predefinedWords):\n",
    "        matched_words_str+=word+'\\n'\n",
    "        matched_word_cnt+=1\n",
    "    inputFile.close()\n",
    "\n",
    "# Writing the output data to the file\n",
    "with open('output.txt','w') as outputFile:\n",
    "    outputFile.write(matched_words_str)\n",
    "    outputFile.close()\n",
    "    \n",
    "endTime = time.time()\n",
    "print('Exec Time:', endTime-startTime)\n",
    "print('Matched words:', matched_word_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EcUJLe6BR8Pv",
    "outputId": "e6bdfa30-f1bf-43c0-a0ea-cbe059280d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/varunreddy/miniconda3/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /Users/varunreddy/miniconda3/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "75dQjF5Jk5Nn",
    "outputId": "116d1462-af6d-4ae9-d410-ca545a9400af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exec Time: 1.1681132316589355\n",
      "Matched words: 27044\n"
     ]
    }
   ],
   "source": [
    "# With Spark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import time\n",
    "\n",
    "# creating a spark session in local\n",
    "startTime = time.time()\n",
    "predefinedFile = 'predefined_words.txt'\n",
    "inputFile = \"input.txt\"\n",
    "spark = SparkSession.builder.master('local[*]').appName(\"Illumio-Assessemnt\").getOrCreate()\n",
    "\n",
    "# reading the data for both the files using spark\n",
    "inputData = spark.read.text(inputFile)\n",
    "predefinedData = spark.read.text(predefinedFile)\n",
    "\n",
    "# inputData.show()\n",
    "# predefinedData.show()\n",
    "\n",
    "# renaming and selecting the word data\n",
    "input_data_table = inputData.select(inputData.value.alias(\"inputWord\"))\n",
    "predefined_data_table = predefinedData.select(predefinedData.value.alias(\"predefinedWord\"))\n",
    "\n",
    "# join operation to get the input words which exist in the predefined data\n",
    "matchedWords = input_data_table.join(predefined_data_table).where(\"inputWord == predefinedWord\").select('inputWord')\n",
    "\n",
    "# writing back to the file\n",
    "matchedWords.write.text('output-spark')\n",
    "\n",
    "endTime = time.time()\n",
    "print('Exec Time:', endTime-startTime)\n",
    "print('Matched words:', matchedWords.count())\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
